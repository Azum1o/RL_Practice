# RL算法代码整理
基于《动手学强化学习》，根据gym版本升级之后部分方法参数及输出的变化进行了修改，将代码各块按功能分类，
并添加了对初学者层面更加浅显易懂的注释，方便个人回顾

***代码环境***
- python == 3.12.4
- gymnasium == 0.29.1
- numpy == 2.1.1
- PyTorch == 2.4.1
- tqdm == 4.66.5
- cuda == 11.2
- matplotlib == 3.9.2

***已经更新部分***
- DQN算法
- 基于Cartpole环境的Dueling DQN算法（事实上应该用Pendulum环境）
- 策略梯度REINFORECE
- A2C
学习笔记可见 https://lor1keet.github.io

持续更新中...
